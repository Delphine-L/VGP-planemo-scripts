# Run Assembly Scripts through the command line

Scripts to run the VGP pipelines through planemo - Do not Support Trio data yet
Designed to import data from the Genomeark AWS repository.

Note : For Pre-Curation Workflow, go to the pre_curation folder after installing the dependencies. 

## Dependencies

See the file installs.sh for the list of dependencies

## First step - Add a species to the file tracking table

You need: 
1. the species name (no space, underscores) (e.g. Taeniopygia_guttata)
2. the assembly ID (e.g. bTaeGut2)
3. the path of the output table (e.g. list_file.tab)

````bash
  sh VGP-planemo-scripts/get_files_names.sh -s  $Species_name -a  $Assembly_ID -o $output 
````

If the output doesn't exist, it will be created, if not the files will be added at the bottom. 

To prepare several species at one, create a tabulated file with the following columns:
1. Species Name
2. Assembly ID

And use awk : 

```bash
  awk -F'\t' '{cmd = "sh get_files_names.sh -s " $1 " -a " $2 " -o  $output "; system(cmd)}' $table_with_species
```


### Output : 

A tabular file containing the names of PacBio, Arima, and Bionano files on Genomark

e.g.

````tabular
Taeniopygia_guttata	bTaeGut2	m54306U_210519_154448.hifi_reads.fastq.gz m54306U_210521_004211.hifi_reads.fastq.gz m54306Ue_210629_211205.hifi_reads.fastq.gz m54306Ue_210719_083927.hifi_reads.fastq.gz m64055e_210624_223222.hifi_reads.fastq.gz	bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L1_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L2_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L3_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L4_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L5_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L6_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L7_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L8_R1.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMMCCXY_L6_R1.fq.gz	bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L1_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L2_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L3_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L4_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L5_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L6_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L7_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMFCCXY_L8_R2.fq.gz bTaeGut2_ARI8_001_USPD16084394-AK5146_HJFMMCCXY_L6_R2.fq.gz	bTaeGut2_Saphyr_DLE1_3172351.cmap
````



## Prepare files for Workflow 1 

Inputs: 
1. The name of the table with the paths to the data (output of the previous step) **(-t)**
2. The target Galaxy instance (e.g. `https://usegalaxy.org/`) **(-g)**
3. The directory containing the workflows **(-w)** If the directory doesn't exist, it will be created. If the workflow file isn't in the directory, the workflow will be downloaded.
3. Optional: Specify a workflow version to use, Default is 0.3 **(-v)**. Warning: Changing this parameter may cause errors if the workflos inputs are different from the default version.
3. Optional: a suffix for the analysis **(-s)** (e.g. `2.0` will produce files called `wf1_$S{assembly_ID}_2.0.yaml`)


Usage: 

````bash
  python prepare_wf1.py -t <Table with file paths> -g <Galaxy url>  -w <Workflow Directory>  -v <Workflow version> -s <Suffix> 
````

### Output : 

For each Species : 
- A Yaml File containing the input paths and the job parameters named `wf1_${assembly_ID}.yml` in the folder `job_files`

For all : 
- A table named `wf_run_${Input_table}` containing the input table plus columns listing : 
  - The yaml file to use for running workflow 1
  - The json file that will contain the results of the workflow 1 run
  - The command line to paste on your shell to run workflow 1 on Galaxy.org. Set or replace `$MAINKEY` variable with your Galaxy API Key.


### Run Workflow 1

- To change a parameter for one species, modify the file `job_files/wf1_${assembly_ID}.yml`. To change the parameters for all jobs, modify the file `wf1_run.sample.yaml` before runing  `prepare_wf1.py`
- Use the generated command line to upload the data and run the workflow. 


>>  WARNING: Disconnecting your terminal before the command finish will interrupt the process!


## Prepare files for workflow 4 (3 in progress) 

> Note: If the json file with the invocation details is missing or in error, but the invocation is successful in Galaxy, add the invocation number to the generated table in the column `Invocation_wf1`. This can happen if: 
>  -  The planemo command for wf1 has been interrupted,
>  -  The Workflow had errors but you fixed it in the interface
> Try this if you get an error `IndexError: list index out of range` when running `prepare_wf4.py`

You need: 
1. The table named `wf_run_$Input_table` generated by `prepare_wf1.py` (-t)
2. The target Galaxy instance (e.g. `https://usegalaxy.org/`)  (-g)
3. The API key for your Galaxy instance  **(-k)**
3. The directory containing the workflows **(-w)** If the directory doesn't exist, it will be created. If the workflow file isn't in the directory, the workflow will be downloaded.
4. Optional: Specify a workflow version to use, Default is 0.3.8 **(-v)**. Warning: Changing this parameter may cause errors if the workflos inputs are different from the default version.
4. Optional: a suffix for the analysis **(-s)** (e.g. `2.0` will produce files called `wf4_$S{assembly_ID}_2.0.yaml` ) 

````bash
  python prepare_wf4.py  -t  <Tracking table>  -k <API Key> -g <Galaxy Instance> -w <workflow directory> -v <Optional workflow version> -s <Optional suffix>
````

> Note: You can run this step even if some of your invocations are not finished. The script will skip lines with incomplete invocations and lines that have already been processed. If you want to re-generate the files and command for a species, delete the file `job_files/w4_${assembly_ID}.yaml`.

To change the parameters of all jobs, modify the file `w4_run.sample.yaml`

### Outputs : 

For each Species : 
- A Yaml File containing the input paths and the job parameters named `wf4_${assembly_ID}.yml` in the folder `job_files`

For all : 
- The updated Tracking table named containing the previous data plus columns listing : 
  - Tha path to the PDF report of WF1 
  - The path to the yaml file to use for running workflow 3 or 4
  - The path to the json file that will contain the results of the workflow 3 or 4 run
  - The command line to paste on your shell to run workflow 3 or 4 on Galaxy. Set or replace `$MAINKEY` variable with your Galaxy API ID.